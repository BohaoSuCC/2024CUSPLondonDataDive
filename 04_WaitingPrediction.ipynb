{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('Data/AQ_CS_All_Full.csv')\n",
    "CSMeta = pd.read_csv('Data/CongestionScoot/Metadata(siteCoordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CS = CSMeta['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Data/CongestionScoot/MergedCSVs/01-857.csv does not exist.\n",
      "File Data/CongestionScoot/MergedCSVs/01-858.csv does not exist.\n",
      "File Data/CongestionScoot/MergedCSVs/12-173.csv does not exist.\n",
      "File Data/CongestionScoot/MergedCSVs/13-077.csv does not exist.\n",
      "File Data/CongestionScoot/MergedCSVs/13-172.csv does not exist.\n",
      "File Data/CongestionScoot/MergedCSVs/23-850.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BigData = pd.DataFrame()\n",
    "Allsites = pd.DataFrame()\n",
    "\n",
    "for i in all_CS:\n",
    "    filenameurl = f\"Data/CongestionScoot/MergedCSVs/{i}.csv\"\n",
    "    if os.path.exists(filenameurl):\n",
    "        df = pd.read_csv(filenameurl)\n",
    "        df['ID'] = i\n",
    "        # 使用df.iloc[[-1]]而不是df.iloc[-1]来保持DataFrame格式\n",
    "        Allsites = pd.concat([Allsites, df.iloc[[-1]]], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"File {filenameurl} does not exist.\")\n",
    "\n",
    "# 循环结束后，进行一次性合并\n",
    "# 确保CSMeta和Allsites都有'ID'列可供合并\n",
    "if not Allsites.empty:\n",
    "    BigData = pd.merge(CSMeta, Allsites, on='ID', how='left')\n",
    "else:\n",
    "    print(\"No sites data available to merge.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "transformer = Transformer.from_crs(\"epsg:27700\", \"epsg:4326\", always_xy=True)\n",
    "BigData['Longitude'], BigData['Latitude'] = zip(*BigData.apply(lambda x: transformer.transform(x['Easting'], x['Northing']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Easting', 'Northing', 'DateTime', 'Date', 'Time', 'SatMean',\n",
       "       'SatBand', 'FlowMean', 'Longitude', 'Latitude', 'SpeciesType',\n",
       "       'SiteType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BigData['SpeciesType']='NO2'\n",
    "BigData['SiteType']='Roadside'\n",
    "BigData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData.to_csv('Data/ForPrediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData.drop(['Easting', 'Northing','DateTime','Time','SatBand','ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018-03-17 23:00,-0.3,80,19.7,52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData['Hour'] = '9'\n",
    "BigData['month'] = '03'\n",
    "BigData['year'] = '2018'\n",
    "BigData['temperature_2m (°C)'] = '-0.3'\n",
    "BigData['relative_humidity_2m (%)'] = '80'\n",
    "BigData['wind_speed_10m (km/h)'] = '19.7'\n",
    "BigData['wind_direction_10m (°)'] = '52'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData.to_csv('Data/ForPrediction2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigData = pd.DataFrame()\n",
    "\n",
    "for i in all_CS:\n",
    "    filenameurl = f\"Data/CongestionScoot/MergedCSVs/{i}.csv\"\n",
    "    if os.path.exists(filenameurl):\n",
    "        df = pd.read_csv(filenameurl)\n",
    "        CSMeta['']\n",
    "        BigData = pd.merge(BigData, df, on='ID', how='outer')\n",
    "    else:\n",
    "        print(f\"File {filenameurl} does not exist.\")\n",
    "        # 或者在这里添加其他处理逻辑，例如添加一个具有默认值的条目"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
