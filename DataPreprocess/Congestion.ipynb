{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do some preliminary data processing on the congestion scoot data. This data is downloaded from https://roads.data.tfl.gov.uk/. This data contains all the traffic congestion data from December 17, 2017 to March 16, 2018. We will do some preliminary processing on this data.\n",
    "\n",
    "\n",
    "我们对 congestion scoot 这个数据进行初步的预处理。这个数据下载来自 https://roads.data.tfl.gov.uk/ 。这个数据包含了从2017年12月17日到2018年3月16日所有的交通拥堵数据。我们将这个数据进行初步的处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import contextily as ctx\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will process the metadata. The metadata is a csv file that contains the observation point id and their coordinate information (represented in the British National Grid coordinate system).\n",
    "\n",
    "首先是对metadata的处理，metadata是一个csv文件，里面包含了所有记录道路拥堵数据的观测点id以及他们的坐标信息（基于British National Grid坐标系统进行表示）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Easting</th>\n",
       "      <th>Northing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>06-034</td>\n",
       "      <td>544674</td>\n",
       "      <td>178944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>30-108</td>\n",
       "      <td>522736</td>\n",
       "      <td>187403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>09-411</td>\n",
       "      <td>529257</td>\n",
       "      <td>175214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>09-059</td>\n",
       "      <td>530186</td>\n",
       "      <td>170859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>05-065</td>\n",
       "      <td>533956</td>\n",
       "      <td>180953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Easting  Northing\n",
       "1168  06-034   544674    178944\n",
       "3928  30-108   522736    187403\n",
       "1838  09-411   529257    175214\n",
       "1665  09-059   530186    170859\n",
       "980   05-065   533956    180953"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "file_path = '../Data/CongestionScoot/Metadata.csv'\n",
    "\n",
    "# read the data\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the Easting and Northing columns are in the correct data type\n",
    "# 确保 Easting 和 Northing 列的数据类型是正确的\n",
    "df['Easting'] = pd.to_numeric(df['Easting'], errors='coerce')\n",
    "df['Northing'] = pd.to_numeric(df['Northing'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 创建点几何列\n",
    "geometry = [Point(xy) for xy in zip(df['Easting'], df['Northing'])]\n",
    "\n",
    "# 创建 GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['Easting'], df['Northing']))\n",
    "\n",
    "\n",
    "# 设置坐标参考系统(CRS)为英国国家网格参考系统 (EPSG:27700)，并转换为WGS84 (EPSG:4326)\n",
    "gdf.crs = 'epsg:27700'\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "# 创建 folium 地图对象\n",
    "m = folium.Map(\n",
    "    location=[gdf.geometry.y.mean(), gdf.geometry.x.mean()], # 设置地图的中心点\n",
    "    zoom_start=10 # 初始缩放级别\n",
    ")\n",
    "\n",
    "\n",
    "# 在地图上添加点\n",
    "for _, row in gdf.iterrows():\n",
    "    \n",
    "    # 创建自定义图标\n",
    "    icon = folium.CustomIcon(\n",
    "    \"location-crosshairs-solid.svg\",\n",
    "    icon_size=(20, 20),\n",
    "    icon_anchor=(10, 10)\n",
    ")\n",
    "    folium.Marker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        icon = icon,\n",
    "        popup=row['ID'] # 假设每个点有一个 'id' 列作为标识\n",
    "    ).add_to(m)\n",
    "\n",
    "# 添加图层切换控件\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# 保存地图到HTML文件\n",
    "m.save('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import pandas as pd\n",
    "\n",
    "# 准备数据\n",
    "data = pd.read_csv('../Data/CongestionScoot/Metadata.csv')  # 假设您的数据在'data.csv'文件中\n",
    "\n",
    "# 创建地图对象\n",
    "m = folium.Map(\n",
    "    location=[gdf.geometry.y.mean(), gdf.geometry.x.mean()], # 设置地图的中心点\n",
    "    zoom_start=10 # 初始缩放级别\n",
    ")\n",
    "\n",
    "# 添加图层\n",
    "for index, row in data.iterrows():\n",
    "    folium.Marker([row['lat'], row['lon']], popup=row['name']).add_to(m)\n",
    "\n",
    "# 添加图层切换控件\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# 保存地图到HTML文件\n",
    "m.save('map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先需要对三个文件夹中的同名文件进行合并，然后对合并后的文件进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件夹路径\n",
    "folders = ['../Data/CongestionScoot/CSV-171217-180115', '../Data/CongestionScoot/CSV2-180116-180214', '../Data/CongestionScoot/CSV3-180215-180316']\n",
    "new_folder = '../Data/CongestionScoot/MergedCSVs'\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 获取每个文件夹中的文件列表\n",
    "files_in_folders = [set(glob.glob(f\"{folder}/*.csv\")) for folder in folders]\n",
    "\n",
    "# 找出所有文件夹中共有的文件名\n",
    "common_files = set.intersection(*files_in_folders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义所有观测点的ID列表\n",
    "all_ids = df['ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/CongestionScoot/CSV-171217-180115/01-857.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 忽略每个文件的前4行\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     11\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/CongestionScoot/CSV-171217-180115/01-857.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 对于每个共有的文件\n",
    "for id in all_ids:\n",
    "    \n",
    "    # 读取并合并文件\n",
    "    dfs = []\n",
    "    for folder in folders:\n",
    "        file_path = f\"{folder}/{id}.csv\"\n",
    "        # 忽略每个文件的前4行\n",
    "        df = pd.read_csv(file_path, skiprows=4)\n",
    "        dfs.append(df)\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # 保存到新文件夹\n",
    "    merged_df.to_csv(f\"{new_folder}/{id}.csv\", index=False)\n",
    "\n",
    "print(\"Merging completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every obervation's recording is in a separate csv file, we will convert the metadata from long table to wide table. This will make it easier for us to process the time series data of each observation point.\n",
    "\n",
    "因为每个记录点的congestion信息都是按照时间进行记录的，而每个记录点是一个单独的csv文件。如果需要对某个观测点的时间序列数据进行处理，我们需要对原csv文件进行某些预处理，将long table转换为wide table。这样我们就可以对某个观测点的时间序列数据进行处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>SatMean</th>\n",
       "      <th>SatBand</th>\n",
       "      <th>FlowMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>43106.885417</td>\n",
       "      <td>6-Jan-2018</td>\n",
       "      <td>21:15</td>\n",
       "      <td>63.75</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>43099.437500</td>\n",
       "      <td>30-Dec-2017</td>\n",
       "      <td>10:30</td>\n",
       "      <td>52.25</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>43087.947917</td>\n",
       "      <td>18-Dec-2017</td>\n",
       "      <td>22:45</td>\n",
       "      <td>64.25</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>43109.718750</td>\n",
       "      <td>9-Jan-2018</td>\n",
       "      <td>17:15</td>\n",
       "      <td>85.00</td>\n",
       "      <td>80-89%</td>\n",
       "      <td>4487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>43114.458333</td>\n",
       "      <td>14-Jan-2018</td>\n",
       "      <td>11:00</td>\n",
       "      <td>86.25</td>\n",
       "      <td>80-89%</td>\n",
       "      <td>4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>43090.750000</td>\n",
       "      <td>21-Dec-2017</td>\n",
       "      <td>18:00</td>\n",
       "      <td>103.25</td>\n",
       "      <td>&gt;= 100%</td>\n",
       "      <td>5529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>43112.489583</td>\n",
       "      <td>12-Jan-2018</td>\n",
       "      <td>11:45</td>\n",
       "      <td>51.00</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>2727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>43088.468750</td>\n",
       "      <td>19-Dec-2017</td>\n",
       "      <td>11:15</td>\n",
       "      <td>90.75</td>\n",
       "      <td>90-99%</td>\n",
       "      <td>5973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DateTime         Date   Time  SatMean  SatBand  FlowMean\n",
       "2006  43106.885417   6-Jan-2018  21:15    63.75    0-79%      3899\n",
       "1291  43099.437500  30-Dec-2017  10:30    52.25    0-79%      2826\n",
       "187   43087.947917  18-Dec-2017  22:45    64.25    0-79%      3883\n",
       "2278  43109.718750   9-Jan-2018  17:15    85.00   80-89%      4487\n",
       "2733  43114.458333  14-Jan-2018  11:00    86.25   80-89%      4978\n",
       "457   43090.750000  21-Dec-2017  18:00   103.25  >= 100%      5529\n",
       "2544  43112.489583  12-Jan-2018  11:45    51.00    0-79%      2727\n",
       "237   43088.468750  19-Dec-2017  11:15    90.75   90-99%      5973"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因为csv文件前几行是无效的，所以需要跳过前几行\n",
    "ObservationPoint = pd.read_csv('../Data/CongestionScoot/CSV-171217-180115/00-005.csv', skiprows=4)\n",
    "ObservationPoint.sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">FlowMean</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">SatMean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:45</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:15</th>\n",
       "      <th>01:30</th>\n",
       "      <th>01:45</th>\n",
       "      <th>02:00</th>\n",
       "      <th>02:15</th>\n",
       "      <th>...</th>\n",
       "      <th>21:30</th>\n",
       "      <th>21:45</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:15</th>\n",
       "      <th>22:30</th>\n",
       "      <th>22:45</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-Jan-2018</th>\n",
       "      <td>1968</td>\n",
       "      <td>2829</td>\n",
       "      <td>2070</td>\n",
       "      <td>1865</td>\n",
       "      <td>1773</td>\n",
       "      <td>1684</td>\n",
       "      <td>1538</td>\n",
       "      <td>1466</td>\n",
       "      <td>1537</td>\n",
       "      <td>1379</td>\n",
       "      <td>...</td>\n",
       "      <td>63.50</td>\n",
       "      <td>47.50</td>\n",
       "      <td>61.50</td>\n",
       "      <td>74.00</td>\n",
       "      <td>56.75</td>\n",
       "      <td>65.50</td>\n",
       "      <td>57.25</td>\n",
       "      <td>54.75</td>\n",
       "      <td>54.75</td>\n",
       "      <td>55.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17-Dec-2017</th>\n",
       "      <td>4835</td>\n",
       "      <td>5223</td>\n",
       "      <td>5189</td>\n",
       "      <td>3827</td>\n",
       "      <td>5176</td>\n",
       "      <td>4365</td>\n",
       "      <td>4323</td>\n",
       "      <td>3789</td>\n",
       "      <td>3655</td>\n",
       "      <td>4081</td>\n",
       "      <td>...</td>\n",
       "      <td>56.50</td>\n",
       "      <td>53.75</td>\n",
       "      <td>46.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>51.75</td>\n",
       "      <td>46.50</td>\n",
       "      <td>55.50</td>\n",
       "      <td>53.50</td>\n",
       "      <td>54.00</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13-Jan-2018</th>\n",
       "      <td>4133</td>\n",
       "      <td>4231</td>\n",
       "      <td>3932</td>\n",
       "      <td>4025</td>\n",
       "      <td>3678</td>\n",
       "      <td>3344</td>\n",
       "      <td>3166</td>\n",
       "      <td>3069</td>\n",
       "      <td>3275</td>\n",
       "      <td>2870</td>\n",
       "      <td>...</td>\n",
       "      <td>75.25</td>\n",
       "      <td>64.50</td>\n",
       "      <td>70.00</td>\n",
       "      <td>73.25</td>\n",
       "      <td>79.75</td>\n",
       "      <td>76.75</td>\n",
       "      <td>69.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>67.50</td>\n",
       "      <td>71.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20-Dec-2017</th>\n",
       "      <td>4263</td>\n",
       "      <td>3484</td>\n",
       "      <td>3547</td>\n",
       "      <td>3371</td>\n",
       "      <td>2813</td>\n",
       "      <td>2881</td>\n",
       "      <td>2328</td>\n",
       "      <td>2630</td>\n",
       "      <td>1969</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>72.00</td>\n",
       "      <td>65.50</td>\n",
       "      <td>72.00</td>\n",
       "      <td>70.75</td>\n",
       "      <td>79.25</td>\n",
       "      <td>73.25</td>\n",
       "      <td>70.50</td>\n",
       "      <td>72.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26-Dec-2017</th>\n",
       "      <td>2526</td>\n",
       "      <td>2602</td>\n",
       "      <td>2149</td>\n",
       "      <td>1785</td>\n",
       "      <td>1432</td>\n",
       "      <td>1352</td>\n",
       "      <td>1318</td>\n",
       "      <td>986</td>\n",
       "      <td>1109</td>\n",
       "      <td>861</td>\n",
       "      <td>...</td>\n",
       "      <td>63.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>55.50</td>\n",
       "      <td>63.00</td>\n",
       "      <td>67.75</td>\n",
       "      <td>53.25</td>\n",
       "      <td>54.25</td>\n",
       "      <td>42.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>33.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27-Dec-2017</th>\n",
       "      <td>2201</td>\n",
       "      <td>1763</td>\n",
       "      <td>2103</td>\n",
       "      <td>1857</td>\n",
       "      <td>1597</td>\n",
       "      <td>1683</td>\n",
       "      <td>1514</td>\n",
       "      <td>1354</td>\n",
       "      <td>1168</td>\n",
       "      <td>1217</td>\n",
       "      <td>...</td>\n",
       "      <td>44.75</td>\n",
       "      <td>45.25</td>\n",
       "      <td>46.50</td>\n",
       "      <td>50.50</td>\n",
       "      <td>52.25</td>\n",
       "      <td>48.25</td>\n",
       "      <td>40.50</td>\n",
       "      <td>44.25</td>\n",
       "      <td>40.50</td>\n",
       "      <td>32.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-Jan-2018</th>\n",
       "      <td>1816</td>\n",
       "      <td>1449</td>\n",
       "      <td>1613</td>\n",
       "      <td>1475</td>\n",
       "      <td>1364</td>\n",
       "      <td>1203</td>\n",
       "      <td>1039</td>\n",
       "      <td>1172</td>\n",
       "      <td>983</td>\n",
       "      <td>805</td>\n",
       "      <td>...</td>\n",
       "      <td>44.00</td>\n",
       "      <td>45.25</td>\n",
       "      <td>45.75</td>\n",
       "      <td>55.25</td>\n",
       "      <td>43.75</td>\n",
       "      <td>34.50</td>\n",
       "      <td>32.75</td>\n",
       "      <td>30.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>39.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25-Dec-2017</th>\n",
       "      <td>2931</td>\n",
       "      <td>3133</td>\n",
       "      <td>2645</td>\n",
       "      <td>2614</td>\n",
       "      <td>2448</td>\n",
       "      <td>2366</td>\n",
       "      <td>1972</td>\n",
       "      <td>1893</td>\n",
       "      <td>1374</td>\n",
       "      <td>1481</td>\n",
       "      <td>...</td>\n",
       "      <td>72.25</td>\n",
       "      <td>66.00</td>\n",
       "      <td>60.25</td>\n",
       "      <td>64.75</td>\n",
       "      <td>66.25</td>\n",
       "      <td>64.75</td>\n",
       "      <td>54.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>52.50</td>\n",
       "      <td>37.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23-Dec-2017</th>\n",
       "      <td>3597</td>\n",
       "      <td>3493</td>\n",
       "      <td>3005</td>\n",
       "      <td>2749</td>\n",
       "      <td>3035</td>\n",
       "      <td>2773</td>\n",
       "      <td>2547</td>\n",
       "      <td>2642</td>\n",
       "      <td>2403</td>\n",
       "      <td>2629</td>\n",
       "      <td>...</td>\n",
       "      <td>61.50</td>\n",
       "      <td>58.50</td>\n",
       "      <td>53.50</td>\n",
       "      <td>57.50</td>\n",
       "      <td>69.50</td>\n",
       "      <td>63.75</td>\n",
       "      <td>57.00</td>\n",
       "      <td>55.50</td>\n",
       "      <td>59.75</td>\n",
       "      <td>58.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FlowMean                                                        \\\n",
       "Time           00:00 00:15 00:30 00:45 01:00 01:15 01:30 01:45 02:00 02:15   \n",
       "Date                                                                         \n",
       "5-Jan-2018      1968  2829  2070  1865  1773  1684  1538  1466  1537  1379   \n",
       "17-Dec-2017     4835  5223  5189  3827  5176  4365  4323  3789  3655  4081   \n",
       "13-Jan-2018     4133  4231  3932  4025  3678  3344  3166  3069  3275  2870   \n",
       "20-Dec-2017     4263  3484  3547  3371  2813  2881  2328  2630  1969  2014   \n",
       "26-Dec-2017     2526  2602  2149  1785  1432  1352  1318   986  1109   861   \n",
       "27-Dec-2017     2201  1763  2103  1857  1597  1683  1514  1354  1168  1217   \n",
       "2-Jan-2018      1816  1449  1613  1475  1364  1203  1039  1172   983   805   \n",
       "25-Dec-2017     2931  3133  2645  2614  2448  2366  1972  1893  1374  1481   \n",
       "23-Dec-2017     3597  3493  3005  2749  3035  2773  2547  2642  2403  2629   \n",
       "\n",
       "             ... SatMean                                                   \\\n",
       "Time         ...   21:30  21:45  22:00  22:15  22:30  22:45  23:00  23:15   \n",
       "Date         ...                                                            \n",
       "5-Jan-2018   ...   63.50  47.50  61.50  74.00  56.75  65.50  57.25  54.75   \n",
       "17-Dec-2017  ...   56.50  53.75  46.75  54.50  51.75  46.50  55.50  53.50   \n",
       "13-Jan-2018  ...   75.25  64.50  70.00  73.25  79.75  76.75  69.00  62.00   \n",
       "20-Dec-2017  ...   72.00  65.50  72.00  70.75  79.25  73.25  70.50  72.00   \n",
       "26-Dec-2017  ...   63.00  47.75  55.50  63.00  67.75  53.25  54.25  42.00   \n",
       "27-Dec-2017  ...   44.75  45.25  46.50  50.50  52.25  48.25  40.50  44.25   \n",
       "2-Jan-2018   ...   44.00  45.25  45.75  55.25  43.75  34.50  32.75  30.00   \n",
       "25-Dec-2017  ...   72.25  66.00  60.25  64.75  66.25  64.75  54.50  46.00   \n",
       "23-Dec-2017  ...   61.50  58.50  53.50  57.50  69.50  63.75  57.00  55.50   \n",
       "\n",
       "                           \n",
       "Time         23:30  23:45  \n",
       "Date                       \n",
       "5-Jan-2018   54.75  55.50  \n",
       "17-Dec-2017  54.00  48.50  \n",
       "13-Jan-2018  67.50  71.00  \n",
       "20-Dec-2017  58.00  60.00  \n",
       "26-Dec-2017  32.25  33.50  \n",
       "27-Dec-2017  40.50  32.75  \n",
       "2-Jan-2018   32.00  39.75  \n",
       "25-Dec-2017  52.50  37.75  \n",
       "23-Dec-2017  59.75  58.75  \n",
       "\n",
       "[9 rows x 192 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ObservationPoint_pivot = ObservationPoint.pivot_table(index='Date', columns='Time', values=['FlowMean','SatMean'])\n",
    "ObservationPoint_pivot.sample(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
