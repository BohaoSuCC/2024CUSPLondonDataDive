{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "from LoadingData import LoadFromAPI\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Quality API: 空气质量接口：\n",
    "\n",
    "help网页： [https://api.erg.ic.ac.uk/AirQuality/help](https://api.erg.ic.ac.uk/AirQuality/help)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Quality - MonitoringLocalAuthority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/MonitoringLocalAuthority.xml.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Information/MonitoringLocalAuthority/GroupName=London', data_format=\"xml\", filename=\"Data/AirQuality/MonitoringLocalAuthority.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析xml文件并且提取有用信息，存储到dataframe中并且保存到csv文件中\n",
    "\n",
    "\n",
    "tree = ET.parse('Data/AirQuality/MonitoringLocalAuthority.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "Autho_data = []\n",
    "for record in root.findall('LocalAuthority'):\n",
    "    name = record.get('LocalAuthorityName')\n",
    "    code = record.get('LocalAuthorityCode')\n",
    "    latitude = record.get('LaCentreLatitude')\n",
    "    longitude = record.get('LaCentreLongitude')\n",
    "    Autho_data.append([name, code])\n",
    "\n",
    "Autho_df = pd.DataFrame(Autho_data, columns=['LocalAuthorityName', 'LocalAuthorityCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Quality - MonitoringSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = http://api.erg.ic.ac.uk/AirQuality/Information/MonitoringSites/GroupName={GROUPNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/MonitoringSites.xml.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='http://api.erg.ic.ac.uk/AirQuality/Information/MonitoringSites/GroupName=London', data_format=\"xml\", filename=\"Data/AirQuality/MonitoringSites.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 您的XML文件路径\n",
    "\n",
    "# 解析XML文件\n",
    "tree = ET.parse('Data/AirQuality/MonitoringSites.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# 提取数据\n",
    "data = []\n",
    "for site in root.findall('Site'):\n",
    "    # 获取属性\n",
    "    local_authority_code = site.get('LocalAuthorityCode')\n",
    "    local_authority_name = site.get('LocalAuthorityName')\n",
    "    site_code = site.get('SiteCode')\n",
    "    site_name = site.get('SiteName')\n",
    "    site_type = site.get('SiteType')\n",
    "    date_opened = site.get('DateOpened')\n",
    "    date_closed = site.get('DateClosed')\n",
    "    latitude = site.get('Latitude')\n",
    "    longitude = site.get('Longitude')\n",
    "    \n",
    "    # 将提取的数据添加到列表中\n",
    "    data.append({\n",
    "        'LocalAuthorityCode': local_authority_code,\n",
    "        'LocalAuthorityName': local_authority_name,\n",
    "        'SiteCode': site_code,\n",
    "        'SiteName': site_name,\n",
    "        'SiteType': site_type,\n",
    "        'DateOpened': date_opened,\n",
    "        'DateClosed': date_closed,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude\n",
    "    })\n",
    "\n",
    "# 创建DataFrame\n",
    "AQ_Sites_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "AQ_Sites_df.to_csv('Data/AirQuality/AQ_Sites.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Quality - Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/MonitoringSiteSpecies.xml.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Information/MonitoringSiteSpecies/GroupName=London', data_format=\"xml\", filename=\"Data/AirQuality/MonitoringSiteSpecies.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Data/AirQuality/MonitoringSiteSpecies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Save the DataFrame to a CSV file\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mData/AirQuality/MonitoringSiteSpecies.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\SBH\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Data/AirQuality/MonitoringSiteSpecies.csv'"
     ]
    }
   ],
   "source": [
    "# Parsing the XML content\n",
    "tree = ET.parse('Data/AirQuality/MonitoringSiteSpecies.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "# Collecting data into a list of dictionaries\n",
    "data = []\n",
    "\n",
    "# Iterate over each site in the XML\n",
    "for site in root.findall('Site'):\n",
    "    site_data = site.attrib  # Get the site attributes\n",
    "    for species in site.findall('Species'):\n",
    "        # Combine site data with species data for each row\n",
    "        species_data = species.attrib\n",
    "        row_data = {**site_data, **species_data}\n",
    "        data.append(row_data)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Data/AirQuality/MonitoringSiteSpecies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/MonitoringReport_BG1_2022.xml.\n"
     ]
    }
   ],
   "source": [
    "# Try one\n",
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Annual/MonitoringObjective/SiteCode=BG1/StartDate=01 Jan 2020', \n",
    "                               data_format=\"xml\", \n",
    "                               filename=\"Data/AirQuality/MonitoringReport_BG1_2022.xml\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data. Status code: 400\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.tfl.gov.uk/AccidentStats/2022', \n",
    "                               data_format=\"json\", \n",
    "                               filename=\"Data/AirQuality/AccidentStats_2022.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the specific species information of specific site during some period fromdate to enddate from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns raw data based on 'SiteCode', 'StartDate', 'EndDate'. Default time period is 'hourly'. Data returned in CSV format\n",
    "\n",
    "\"https://api.erg.ic.ac.uk/AirQuality/Data/Site/Wide/SiteCode={SITECODE}/StartDate={STARTDATE}/EndDate={ENDDATE}/csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/BQ7_20180101.xml.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Data/SiteSpecies/SiteCode=BQ7/SpeciesCode=PM25/StartDate=01 Mar 2022/EndDate=01 Apr 2023', \n",
    "                               data_format=\"xml\", \n",
    "                               filename=\"Data/AirQuality/BQ7_20180101.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/BQ7_20180101.csv.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Data/SiteSpecies/SiteCode=BQ7/SpeciesCode=PM25/StartDate=01 Mar 2022/EndDate=01 Apr 2023/csv', \n",
    "                               data_format=\"csv\", \n",
    "                               filename=\"Data/AirQuality/BQ7_20180101.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pivot the long format data to wide format data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MeasurementDateGMT', 'Bexley - Belvedere West: PM2.5 Particulate (ug/m3)'], dtype='object')\n",
      "MeasurementDateGMT\n",
      "Bexley - Belvedere West: PM2.5 Particulate (ug/m3)\n"
     ]
    }
   ],
   "source": [
    "# read data from csv file\n",
    "df = pd.read_csv('Data/AirQuality/BQ7_20180101.csv')\n",
    "print(df.columns)\n",
    "\n",
    "MeasurementDateGMT = df.columns[0]\n",
    "print(MeasurementDateGMT)\n",
    "field = df.columns[1]\n",
    "print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour        00:00  01:00  02:00  03:00  04:00  05:00  06:00  07:00  08:00  \\\n",
      "date                                                                        \n",
      "2022-05-04   13.3   13.9   15.4   20.2   21.3   20.5   22.7   28.3   31.9   \n",
      "2022-03-14    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-10-29    6.8    5.3    5.3    6.0    6.3    6.0    6.3    6.7    7.9   \n",
      "2022-03-23    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-04-22    8.3    9.7   11.6   12.7   13.4   14.9   16.8   15.4   14.8   \n",
      "2022-11-18    3.0    2.8    2.9    2.7    2.5    2.4    2.5    2.7    2.9   \n",
      "2023-02-09   23.8   23.8   23.0   22.4   21.5   20.4   18.1   18.4   18.9   \n",
      "2022-12-17   36.3   34.0   30.4   27.4   26.6   25.2   17.1    4.4    4.6   \n",
      "2023-01-10    8.9    8.3    7.8    7.6    7.1    7.4    7.9    7.8    5.4   \n",
      "2023-01-13    6.7    5.3    6.1    6.2    6.8    6.4    6.1    6.5    6.5   \n",
      "2022-11-23    6.4    5.9    5.5    4.7    3.6    4.0    4.7    4.4    2.0   \n",
      "2022-05-30    4.4    5.0    4.5    4.8    4.1    3.6    3.3    2.5    2.7   \n",
      "2023-03-24    4.3    5.8    6.3    6.6    7.6    8.3    8.3    7.8    6.9   \n",
      "2022-03-17    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-08-04    4.0    4.0    4.1    4.2    4.4    5.3    4.9    4.7    5.0   \n",
      "\n",
      "hour        09:00  ...  14:00  15:00  16:00  17:00  18:00  19:00  20:00  \\\n",
      "date               ...                                                    \n",
      "2022-05-04   25.7  ...    7.6    6.7    5.2    5.6    5.8    6.0    5.3   \n",
      "2022-03-14    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-10-29    8.7  ...   10.4   12.2   13.3   15.8   14.7   15.5   16.8   \n",
      "2022-03-23    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-04-22   13.3  ...    9.7   13.2   10.3    8.6    7.3    7.2    8.7   \n",
      "2022-11-18    3.3  ...    2.7    3.0    3.0    2.4    4.7    4.8    4.8   \n",
      "2023-02-09   20.9  ...    7.9    5.0    6.6    8.7    7.0    8.5    8.9   \n",
      "2022-12-17    5.6  ...   10.0    9.2   12.2   14.8   17.6   15.2   18.5   \n",
      "2023-01-10    2.6  ...   10.2    7.3    8.2    6.1    2.3    1.6    1.4   \n",
      "2023-01-13    6.1  ...    4.8    5.1    5.5    6.6    7.6    8.2    8.6   \n",
      "2022-11-23    1.2  ...    5.6    5.3    5.0    6.2    8.2    9.5    7.0   \n",
      "2022-05-30    2.6  ...    2.4    2.6    2.9    2.7    2.2    2.0    3.9   \n",
      "2023-03-24    6.3  ...    4.1    4.5    5.1    2.2    1.7    3.7    6.4   \n",
      "2022-03-17    NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2022-08-04    4.8  ...    3.6    3.1    3.5    3.2    3.0    2.9    3.1   \n",
      "\n",
      "hour        21:00  22:00  23:00  \n",
      "date                             \n",
      "2022-05-04    4.3    5.3    6.3  \n",
      "2022-03-14    NaN    NaN    NaN  \n",
      "2022-10-29   15.1   12.4    9.7  \n",
      "2022-03-23    NaN    NaN    NaN  \n",
      "2022-04-22    9.4   10.9   12.5  \n",
      "2022-11-18    5.1    5.3    5.1  \n",
      "2023-02-09    9.8   11.3   14.5  \n",
      "2022-12-17   19.1   18.6   19.9  \n",
      "2023-01-10    1.2    1.9    2.4  \n",
      "2023-01-13    8.8    8.8    8.4  \n",
      "2022-11-23    7.7    7.7    6.3  \n",
      "2022-05-30    7.2    6.0    4.9  \n",
      "2023-03-24    6.8    5.7    5.1  \n",
      "2022-03-17    NaN    NaN    NaN  \n",
      "2022-08-04    2.9    3.3    3.6  \n",
      "\n",
      "[15 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the 'MeasurementDateGMT' to datetime to extract date and hour\n",
    "df['MeasurementDateGMT'] = pd.to_datetime(df['MeasurementDateGMT'])\n",
    "\n",
    "# Extract hour as a string with format 'HH:MM' to use as column names\n",
    "df['hour'] = df['MeasurementDateGMT'].dt.strftime('%H:%M')\n",
    "\n",
    "# Create a date column from the 'MeasurementDateGMT' datetime\n",
    "df['date'] = df['MeasurementDateGMT'].dt.date\n",
    "\n",
    "# Pivot the DataFrame to get the wide format with date as index\n",
    "df_wide = df.pivot(index='date', columns='hour', values='Bexley - Belvedere West: PM2.5 Particulate (ug/m3)')\n",
    "\n",
    "# 查看随机几行数据\n",
    "print(df_wide.sample(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Data/AirQuality/BQ7_20180101.csv.\n"
     ]
    }
   ],
   "source": [
    "LoadFromAPI.load_data_from_api(url='https://api.erg.ic.ac.uk/AirQuality/Data/SiteSpecies/SiteCode=BT8/SpeciesCode=NO2/StartDate=01 Mar 2022/EndDate=01 Apr 2023/csv', \n",
    "                               data_format=\"csv\", \n",
    "                               filename=\"Data/AirQuality/BQ7_20180101.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential thing for air quality data\n",
    "\n",
    "https://www.data.gov.uk/dataset/ef87da6c-0b01-4717-aab4-a076e8b8ff7e/london-atmospheric-emissions-inventory-laei-2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London Roads Data\n",
    "\n",
    "[London Roads Data](https://roads.data.tfl.gov.uk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fid  HA_ID               Borough  Version  Changed_on  \\\n",
      "0     5     19               BROMLEY        1  2007-08-15   \n",
      "1   106     18                BEXLEY        3  2014-08-01   \n",
      "2   117     16    BARKING & DAGENHAM        3  2015-05-05   \n",
      "3   122     21                SUTTON        9  2015-05-05   \n",
      "4   139      2                CAMDEN        6  2016-05-25   \n",
      "5   147     12  KENSINGTON & CHELSEA        4  2016-05-25   \n",
      "6   151     22                MERTON        7  2016-05-25   \n",
      "7   152     24  RICHMOND UPON THAMES        4  2016-05-25   \n",
      "8   168      5         TOWER HAMLETS        7  2016-10-24   \n",
      "9   170     14             REDBRIDGE        4  2016-10-24   \n",
      "10  176     26            HILLINGDON        2  2017-04-14   \n",
      "11  177     28                 BRENT        3  2017-04-18   \n",
      "12  183     15              HAVERING        7  2017-07-03   \n",
      "13  189      6             GREENWICH        5  2018-03-16   \n",
      "14  193      8             SOUTHWARK       15  2018-03-21   \n",
      "15  196     20               CROYDON        7  2018-08-20   \n",
      "16  201     23  KINGSTON UPON THAMES        5  2019-04-08   \n",
      "17  204      4               HACKNEY       14  2019-08-08   \n",
      "18  205      0        CITY OF LONDON        6  2020-01-07   \n",
      "19  206     25              HOUNSLOW        4  2020-01-07   \n",
      "20  208      1           WESTMINSTER        4  2020-01-07   \n",
      "21  210     17                NEWHAM        5  2020-03-02   \n",
      "22  213     31              HARINGEY        9  2021-02-23   \n",
      "23  214      3             ISLINGTON       12  2021-02-23   \n",
      "24  216      7              LEWISHAM       10  2022-05-17   \n",
      "25  217      9               LAMBETH       19  2022-05-20   \n",
      "26  218     30                BARNET        6  2022-05-20   \n",
      "27  219     10            WANDSWORTH        8  2023-02-24   \n",
      "28  220     32               ENFIELD        9  2017-02-24   \n",
      "29  226     27                EALING        8  2023-02-27   \n",
      "30  227     11  HAMMERSMITH & FULHAM        4  2023-02-28   \n",
      "31  230     13        WALTHAM FOREST        8  2023-03-02   \n",
      "\n",
      "                                Description_of_Change Effective_From  \\\n",
      "0                                                         2007-08-15   \n",
      "1   Expanded outward to take in fotpath and ditch ...     2014-04-08   \n",
      "2                               See share point ID 34     2015-03-11   \n",
      "3                                See sharepoint ID 14     2014-03-26   \n",
      "4                              see share point ID 101     2016-05-25   \n",
      "5                              see share point ID 101     2016-05-25   \n",
      "6                              see share point ID 101     2016-05-25   \n",
      "7                              see share point ID 101     2016-05-25   \n",
      "8                              see share point ID 106     2016-10-24   \n",
      "9                                See sharepoint ID 48     2016-10-24   \n",
      "10                             SEE SHARE POINT ID 118     2017-04-01   \n",
      "11                             SEE SHARE POINT ID 124     2017-04-12   \n",
      "12                              See share point ID 55     2017-07-03   \n",
      "13                             see share point ID 133     2018-03-16   \n",
      "14                             see share point ID 143     2018-03-21   \n",
      "15                        see share point ID 131, 132     2018-08-20   \n",
      "16                             see share point ID 157     2016-12-25   \n",
      "17                            see share point ID  155     2019-08-08   \n",
      "18                             SEE SHARE POINT ID 160     2020-01-07   \n",
      "19                             see share point ID 135     2020-01-07   \n",
      "20                              see sharepoint ID 159     2020-01-07   \n",
      "21                              see sharepoint ID 161     2020-03-02   \n",
      "22                   correction at islington boundary     2021-02-23   \n",
      "23                        See share point ID 162, 242     2021-01-20   \n",
      "24                             see share point ID 224     2021-05-12   \n",
      "25                             see share point ID 221     2021-03-21   \n",
      "26                             see share point ID 139     2022-05-20   \n",
      "27                             see share point ID 222     2023-02-24   \n",
      "28                             see share point ID 228     2023-02-24   \n",
      "29                             See share point ID 220     2023-02-27   \n",
      "30                             see share point ID 220     2023-02-28   \n",
      "31                             see share point ID 225     2023-03-02   \n",
      "\n",
      "    Effective_To                    Owner Sharepoint_ID  \\\n",
      "0            NaN                                    NaN   \n",
      "1            NaN   huw.harries@tfl.gov.uk           214   \n",
      "2            NaN   huw.harries@tfl.gov.uk            23   \n",
      "3            NaN   huw.harries@tfl.gov.uk             6   \n",
      "4            NaN   huw.harries@tfl.gov.uk            82   \n",
      "5            NaN   huw.harries@tfl.gov.uk            82   \n",
      "6            NaN   huw.harries@tfl.gov.uk            82   \n",
      "7            NaN   huw.harries@tfl.gov.uk            82   \n",
      "8            NaN   huw.harries@tfl.gov.uk            87   \n",
      "9            NaN   huw.harries@tfl.gov.uk            34   \n",
      "10           NaN   huw.harries@tfl.gov.uk            98   \n",
      "11           NaN   huw.harries@tfl.gov.uk           103   \n",
      "12           NaN   huw.harries@tfl.gov.uk            41   \n",
      "13           NaN   huw.harries@tfl.gov.uk           111   \n",
      "14           NaN   huw.harries@tfl.gov.uk           121   \n",
      "15           NaN  shaynameyers@tfl.gov.uk       109,110   \n",
      "16           NaN  shaynameyers@tfl.gov.uk           134   \n",
      "17           NaN  shaynameyers@tfl.gov.uk           132   \n",
      "18           NaN  shaynameyers@tfl.gov.uk           136   \n",
      "19           NaN  shaynameyers@tfl.gov.uk           113   \n",
      "20           NaN  shaynameyers@tfl.gov.uk           135   \n",
      "21           NaN  shaynameyers@tfl.gov.uk           137   \n",
      "22           NaN  shaynameyers@tfl.gov.uk       138,218   \n",
      "23           NaN  shaynameyers@tfl.gov.uk       138,218   \n",
      "24           NaN  shaynameyers@tfl.gov.uk           224   \n",
      "25           NaN  shaynameyers@tfl.gov.uk           221   \n",
      "26           NaN  shaynameyers@tfl.gov.uk           139   \n",
      "27           NaN  shaynameyers@tfl.gov.uk           222   \n",
      "28           NaN  shaynameyers@tfl.gov.uk           228   \n",
      "29           NaN  shaynameyers@tfl.gov.uk           220   \n",
      "30           NaN  shaynameyers@tfl.gov.uk           220   \n",
      "31           NaN  shaynameyers@tfl.gov.uk           225   \n",
      "\n",
      "                                             geometry  \n",
      "0   MULTIPOLYGON (((539407.130 170607.530, 539430....  \n",
      "1   MULTIPOLYGON (((545017.910 175087.950, 545025....  \n",
      "2   MULTIPOLYGON (((547859.740 189107.870, 547919....  \n",
      "3   MULTIPOLYGON (((526050.840 166775.410, 526076....  \n",
      "4   MULTIPOLYGON (((529814.850 184996.890, 529815....  \n",
      "5   MULTIPOLYGON (((523869.920 179849.950, 523900....  \n",
      "6   MULTIPOLYGON (((524704.890 166952.690, 524705....  \n",
      "7   MULTIPOLYGON (((518993.850 177841.740, 518992....  \n",
      "8   MULTIPOLYGON (((538317.930 181349.480, 538289....  \n",
      "9   MULTIPOLYGON (((539489.090 190404.530, 539490....  \n",
      "10  MULTIPOLYGON (((511380.840 184499.120, 511386....  \n",
      "11  MULTIPOLYGON (((522572.170 187266.960, 522592....  \n",
      "12  MULTIPOLYGON (((548889.210 189051.570, 548889....  \n",
      "13  MULTIPOLYGON (((545025.740 175130.550, 545005....  \n",
      "14  MULTIPOLYGON (((535618.500 180784.420, 535603....  \n",
      "15  MULTIPOLYGON (((529845.310 159221.800, 529844....  \n",
      "16  MULTIPOLYGON (((522045.410 167926.120, 522054....  \n",
      "17  MULTIPOLYGON (((532979.380 182586.040, 533013....  \n",
      "18  MULTIPOLYGON (((533456.410 180718.600, 533455....  \n",
      "19  MULTIPOLYGON (((510038.020 176979.760, 510039....  \n",
      "20  MULTIPOLYGON (((530279.720 178998.210, 530273....  \n",
      "21  MULTIPOLYGON (((543859.410 182614.950, 543863....  \n",
      "22  MULTIPOLYGON (((534310.770 189496.340, 534304....  \n",
      "23  MULTIPOLYGON (((532961.430 182538.260, 532959....  \n",
      "24  MULTIPOLYGON (((540636.240 174049.680, 540630....  \n",
      "25  MULTIPOLYGON (((532647.360 173058.110, 532647....  \n",
      "26  MULTIPOLYGON (((521120.760 196704.250, 521122....  \n",
      "27  MULTIPOLYGON (((526987.330 177382.470, 526996....  \n",
      "28  MULTIPOLYGON (((536127.850 192299.970, 536111....  \n",
      "29  MULTIPOLYGON (((511214.550 183823.030, 511216....  \n",
      "30  MULTIPOLYGON (((521899.440 178259.710, 521899....  \n",
      "31  MULTIPOLYGON (((537572.710 185509.510, 537622....  \n"
     ]
    }
   ],
   "source": [
    "geojson_file_path = \"Data/GLA_TLRN_HAB.geojson\"\n",
    "\n",
    "# 加载GeoJSON数据\n",
    "gdf = gpd.read_file(geojson_file_path)\n",
    "\n",
    "# 打印数据帧的前几行，查看数据结构\n",
    "print(gdf.head(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive GUI for London Roads Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def update_label():\n",
    "    label.config(text=\"你好，Tkinter!\")\n",
    "\n",
    "# 创建主窗口\n",
    "root = tk.Tk()\n",
    "root.title(\"Tkinter 示例\")\n",
    "\n",
    "# 设置窗口大小\n",
    "root.geometry(\"300x150\")\n",
    "\n",
    "# 创建标签组件\n",
    "label = tk.Label(root, text=\"点击按钮更改这里的文本\")\n",
    "label.pack()\n",
    "\n",
    "# 创建按钮组件，点击按钮时调用update_label函数\n",
    "button = tk.Button(root, text=\"点击我\", command=update_label)\n",
    "button.pack()\n",
    "\n",
    "# 启动事件循环\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x27876e9f0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入Dash库\n",
    "import dash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# 初始化Dash应用\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# 定义应用布局\n",
    "app.layout = html.Div([\n",
    "    dcc.Input(id='input-text', value='初始文本', type='text'),\n",
    "    html.Div(id='output')\n",
    "])\n",
    "\n",
    "# 添加回调函数来更新输出标签\n",
    "@app.callback(\n",
    "    Output(component_id='output', component_property='children'),\n",
    "    [Input(component_id='input-text', component_property='value')]\n",
    ")\n",
    "def update_output_div(input_value):\n",
    "    return f'你输入了: {input_value}'\n",
    "\n",
    "# 运行应用\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
